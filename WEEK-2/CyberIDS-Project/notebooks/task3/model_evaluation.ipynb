{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec30195-9197-4453-90f0-90b7f071506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\nandu\\OneDrive\\Desktop\\processed_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Debugging: Check dataset\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Label unique values:\", df['Label'].unique())\n",
    "\n",
    "# Remove NaN values from 'Label' column\n",
    "df.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "# Convert labels to numeric (0 = Benign, 1 = Attack)\n",
    "df.loc[:, 'Label'] = df['Label'].astype(float)  # Ensure float for processing\n",
    "df.loc[:, 'Label'] = df['Label'].fillna(df['Label'].mode()[0])  # Fill missing values\n",
    "df.loc[:, 'Label'] = df['Label'].astype(int)  # Convert back to integer\n",
    "\n",
    "# Final check for missing values\n",
    "if df['Label'].isnull().sum() > 0:\n",
    "    raise ValueError(\"ERROR: 'Label' column still contains NaN values. Please check the dataset.\")\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Debugging: Check dataset after preprocessing\n",
    "print(\"Processed dataset shape:\", X.shape)\n",
    "print(\"Target variable stats:\", y.value_counts())\n",
    "\n",
    "# Split data into training & testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Debugging: Verify train-test split\n",
    "print(\"Train size:\", X_train.shape, y_train.shape)\n",
    "print(\"Test size:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Define models with **Decision Tree regularization** to limit overfitting\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree (Pruned)\": DecisionTreeClassifier(max_depth=10, min_samples_split=10),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True)  # Enable probability estimates for ROC curves\n",
    "}\n",
    "\n",
    "# Store evaluation metrics\n",
    "metrics_list = []\n",
    "roc_curves = {}\n",
    "\n",
    "# Train and evaluate models using **cross-validation** for robustness\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalize features\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    #  Perform cross-validation\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "\n",
    "    # Debugging: Verify predictions\n",
    "    print(f\"{name} - Accuracy: {np.mean(y_pred == y_test):.4f}, CV Score: {cv_score:.4f}\")\n",
    "\n",
    "    #  Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Benign\", \"Attack\"], yticklabels=[\"Benign\", \"Attack\"])\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(f\"conf_matrix_{name.lower().replace(' ', '_')}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    #  ROC Curve & AUC Score\n",
    "    if y_pred_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        roc_curves[name] = (fpr, tpr, auc_score)\n",
    "\n",
    "    # Store evaluation metrics dynamically\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    attack_class = str(y_test.max())  # Preserve float format\n",
    "\n",
    "    metrics_list.append([\n",
    "        name, \n",
    "        report[\"accuracy\"], \n",
    "        report[attack_class][\"precision\"], \n",
    "        report[attack_class][\"recall\"], \n",
    "        report[attack_class][\"f1-score\"], \n",
    "        cv_score  # Add Cross-validation score\n",
    "    ])\n",
    "\n",
    "# Plot ROC Curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, (fpr, tpr, auc_score) in roc_curves.items():\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC: {auc_score:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Binary Classification Models\")\n",
    "plt.legend()\n",
    "plt.savefig(\"roc_curves.png\")\n",
    "plt.close()\n",
    "\n",
    "# Save model comparison metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Cross-Validation Score\"])\n",
    "metrics_df.to_csv(\"model_comparison.csv\", index=False)\n",
    "\n",
    "print(\"Model training & evaluation complete! Metrics saved to 'model_comparison.csv'. ROC and Confusion Matrix plots saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714837c-020f-41f6-ae65-f80bcf486e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS C:\\Users\\nandu\\OneDrive\\Desktop> python binary_models.py\n",
    "Dataset loaded successfully.\n",
    "Dataset shape: (1044751, 15)\n",
    "Label unique values: [0. 1.]\n",
    "Processed dataset shape: (1044751, 14)\n",
    "Target variable stats: Label\n",
    "0.0    663808\n",
    "1.0    380943\n",
    "Name: count, dtype: int64\n",
    "Train size: (835800, 14) (835800,)\n",
    "Test size: (208951, 14) (208951,)\n",
    "Logistic Regression - Accuracy: 0.9997, CV Score: 0.9996\n",
    "Decision Tree (Pruned) - Accuracy: 1.0000, CV Score: 1.0000\n",
    "Random Forest - Accuracy: 1.0000, CV Score: 1.0000\n",
    "K-Nearest Neighbors - Accuracy: 1.0000, CV Score: 1.0000\n",
    "SVM - Accuracy: 0.9998, CV Score: 0.9998\n",
    "Model training & evaluation complete! Metrics saved to 'model_comparison.csv'. ROC and Confusion Matrix plots saved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
